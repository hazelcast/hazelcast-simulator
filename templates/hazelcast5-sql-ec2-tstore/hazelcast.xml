<?xml version="1.0" encoding="UTF-8"?>
<hazelcast xmlns="http://www.hazelcast.com/schema/config"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           xsi:schemaLocation="http://www.hazelcast.com/schema/config
           http://www.hazelcast.com/schema/config/hazelcast-config-5.3.xsd">

    <cluster-name>workers</cluster-name>

    <!-- Don't remove the comment below. The lite member configuration is auto-filled by Simulator using this marker. -->
    <!--LITE_MEMBER_CONFIG-->

    <serialization>
        <data-serializable-factories>
            <data-serializable-factory factory-id="1">
                com.hazelcast.simulator.hz.IdentifiedDataSerializableFactory
            </data-serializable-factory>
        </data-serializable-factories>
        <compact-serialization>
            <serializers>
                <serializer>
                    com.hazelcast.simulator.hz.LongCompactSerializer
                </serializer>
                <serializer>
                    com.hazelcast.simulator.hz.MultiFieldCompactSerializer
                </serializer>
            </serializers>
        </compact-serialization>
    </serialization>

    <network>
        <port port-count="200" auto-increment="true">5701</port>
        <join>
            <multicast enabled="false"/>
            <tcp-ip enabled="true">
                <!-- Don't remove the comment below. The IP addresses of the members are auto-filled by Simulator using this marker. -->
                <!--MEMBERS-->
            </tcp-ip>
        </join>
    </network>

    <properties>
        <property name="hazelcast.phone.home.enabled">false</property>
        <property name="hazelcast.logging.type">jdk</property>

    </properties>

    <!-- Don't remove the comment below. The license key is auto-filled by Simulator using this marker. -->
    <!--LICENSE-KEY-->

    <map name="default">
        <in-memory-format>NATIVE</in-memory-format>
        <tiered-store enabled="true">
            <memory-tier>
                <capacity unit="GIGABYTES" value="4"/>
            </memory-tier>
            <disk-tier enabled="true" device-name="default-tiered-store-device"/>
        </tiered-store>
    </map>
    <map name="JoinBenchmark">
        <in-memory-format>NATIVE</in-memory-format>
    </map>

    <local-device name="default-tiered-store-device">
        <base-dir>/home/ubuntu/tiered-store</base-dir>
    </local-device>

    <native-memory enabled="true" allocator-type="POOLED">
        <capacity unit="GIGABYTES" value="16"/>
    </native-memory>

    <jet enabled="true" resource-upload-enabled="false">
		    <!--    <cooperative-thread-count>8</cooperative-thread-count> -->
        <!-- time spacing of flow-control (ack) packets -->
        <flow-control-period>100</flow-control-period>
        <!-- number of backup copies to configure for Hazelcast IMaps used internally in a Jet job -->
        <backup-count>1</backup-count>
        <!-- the delay after which auto-scaled jobs will restart if a new member is added to the
             cluster. The default is 10 seconds. Has no effect on jobs with auto scaling disabled -->
        <scale-up-delay-millis>10000</scale-up-delay-millis>
        <!-- Sets whether Lossless Job Restart is enabled for the node. With
             Lossless Restart, Jet persists job snapshots to disk automatically
             and you can restart the whole cluster without losing the jobs and
             their state.

             This feature requires Hazelcast Enterprise and is implemented on top of the
             Persistence feature. Therefore you should enable and configure Persistence,
             especially the base directory where to store the recovery files.
         -->
        <lossless-restart-enabled>false</lossless-restart-enabled>
        <!-- Sets the maximum number of records that can be accumulated by any single
             Processor instance.
             Operations like grouping, sorting or joining require certain amount of
             records to be accumulated before they can proceed. You can set this option
             to reduce the probability of OutOfMemoryError.

             This option applies to each Processor instance separately, hence the
             effective limit of records accumulated by each cluster member is influenced
             by the vertex's localParallelism and the number of jobs in the cluster.

             Currently, maxProcessorAccumulatedRecords limits:
                - number of items sorted by the sort operation
                - number of distinct keys accumulated by aggregation operations
                - number of entries in the hash-join lookup tables
                - number of entries in stateful transforms
                - number of distinct items in distinct operation

             Note: the limit does not apply to streaming aggregations.
         -->
        <max-processor-accumulated-records>9223372036854775807</max-processor-accumulated-records>
        <edge-defaults>
            <!-- capacity of the concurrent SPSC queue between each two processors -->
            <queue-size>1024</queue-size>

            <!-- network packet size limit in bytes, only applies to distributed edges -->
            <packet-size-limit>16384</packet-size-limit>

            <!-- receive window size multiplier, only applies to distributed edges -->
            <receive-window-multiplier>3</receive-window-multiplier>
        </edge-defaults>
    </jet>
</hazelcast>

